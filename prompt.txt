

# ğŸš¦ Traffic-Mind: Complete GitHub Copilot Mega-Prompt

## Copy Everything Below and Paste into Copilot Chat

---

```
=======================================================================
PROJECT: "Traffic-Mind" â€” AI-Powered Reinforcement Learning Traffic 
         Light Controller with Hardware Integration
=======================================================================

Build me a COMPLETE, PRODUCTION-READY project from scratch.
I need every single file, every line of code, fully working.
Do NOT skip any file. Do NOT say "implement this yourself."
Write COMPLETE code for everything.

=======================================================================
PROJECT STRUCTURE â€” CREATE EXACTLY THIS:
=======================================================================

traffic-mind/
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py              # All constants & hyperparameters
â”‚
â”œâ”€â”€ simulation/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ road_network.py          # Road, Lane, Intersection classes
â”‚   â”œâ”€â”€ vehicle.py               # Vehicle spawning, movement, physics
â”‚   â”œâ”€â”€ traffic_light.py         # Traffic light states & transitions
â”‚   â””â”€â”€ environment.py           # Main simulation environment (Gym-compatible)
â”‚
â”œâ”€â”€ controllers/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ timer_controller.py      # Dumb fixed-timer baseline
â”‚   â”œâ”€â”€ rule_based_controller.py # Smart density-based rules
â”‚   â””â”€â”€ dqn_controller.py        # Deep Q-Network RL agent
â”‚
â”œâ”€â”€ ai/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ dqn_network.py           # Neural network architecture
â”‚   â”œâ”€â”€ replay_buffer.py         # Experience replay memory
â”‚   â””â”€â”€ trainer.py               # Training loop with logging
â”‚
â”œâ”€â”€ hardware/
â”‚   â”œâ”€â”€ arduino_bridge.py        # Python â†” Arduino serial comm
â”‚   â””â”€â”€ traffic_light.ino        # Arduino code for LEDs + IR sensors
â”‚
â”œâ”€â”€ visualization/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ renderer.py              # PyGame rendering engine
â”‚   â”œâ”€â”€ dashboard.py             # Live stats overlay
â”‚   â””â”€â”€ assets/
â”‚       â””â”€â”€ (car sprites, road textures â€” generate programmatically)
â”‚
â”œâ”€â”€ analytics/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ metrics.py               # Throughput, wait time, comparisons
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ (saved trained models go here)
â”‚
â”œâ”€â”€ main.py                      # Main entry point
â”œâ”€â”€ train.py                     # Training script
â””â”€â”€ demo.py                      # Hackathon demo script (one-click)

=======================================================================
FILE 1: config/settings.py
=======================================================================

Create a comprehensive configuration file with ALL constants:

WINDOW SETTINGS:
- SCREEN_WIDTH = 1200
- SCREEN_HEIGHT = 800
- FPS = 60
- BACKGROUND_COLOR = (30, 30, 30)  # Dark theme

ROAD SETTINGS:
- ROAD_WIDTH = 80  (pixels, each direction)
- LANE_WIDTH = 40
- NUM_LANES = 2  (per direction)
- INTERSECTION_SIZE = calculated from road width

VEHICLE SETTINGS:
- CAR_LENGTH = 30
- CAR_WIDTH = 18
- CAR_SPEED_MIN = 2.0
- CAR_SPEED_MAX = 4.0
- CAR_COLORS = list of 8-10 distinct colors
- SPAWN_RATE_LOW = 0.02  (probability per frame)
- SPAWN_RATE_MEDIUM = 0.05
- SPAWN_RATE_HIGH = 0.08
- MAX_VEHICLES = 200
- SAFE_DISTANCE = 10  (pixels between cars)

TRAFFIC LIGHT SETTINGS:
- GREEN_DURATION_TIMER = 90  (frames, for dumb controller)
- YELLOW_DURATION = 30  (frames)
- MIN_GREEN_DURATION = 30  (frames, for AI)
- MAX_GREEN_DURATION = 180  (frames, for AI)
- LIGHT_RADIUS = 12
- LIGHT_COLORS: RED = (255, 0, 0), YELLOW = (255, 255, 0), 
                GREEN = (0, 255, 0)

DQN HYPERPARAMETERS:
- STATE_SIZE = 12
  (4 directions Ã— 3 features: vehicle_count, avg_wait_time, 
   queue_length)
- ACTION_SIZE = 4
  (0: NS_green, 1: EW_green, 2: NS_left_turn, 3: all_red_transition)
  OR simplified to 2 actions: (0: NS_green, 1: EW_green)
- LEARNING_RATE = 0.001
- GAMMA = 0.95  (discount factor)
- EPSILON_START = 1.0
- EPSILON_END = 0.01
- EPSILON_DECAY = 0.995
- BATCH_SIZE = 64
- MEMORY_SIZE = 10000
- TARGET_UPDATE_FREQ = 100  (steps)
- HIDDEN_LAYERS = [128, 128]

REWARD FUNCTION:
- REWARD_CAR_PASSED = +1.0
- PENALTY_CAR_WAITING = -0.1 (per car per step)
- PENALTY_LONG_WAIT = -0.5 (if any car waits > threshold)
- PENALTY_SWITCH = -0.2 (discourage rapid switching)
- REWARD_THROUGHPUT_BONUS = +2.0 (if throughput > threshold)

HARDWARE:
- SERIAL_PORT = 'COM3'  # or '/dev/ttyUSB0' for Linux
- BAUD_RATE = 9600
- HARDWARE_ENABLED = False  # Toggle hardware mode

DIRECTIONS (enum or constants):
- NORTH = 0, SOUTH = 1, EAST = 2, WEST = 3

=======================================================================
FILE 2: simulation/road_network.py
=======================================================================

Build the road network for a SINGLE 4-way intersection:

class Lane:
    - direction: which way cars travel (N, S, E, W)
    - start_pos: (x, y) where cars spawn
    - end_pos: (x, y) where cars despawn (after crossing)
    - waypoints: list of (x, y) points cars follow
    - vehicles: list of Vehicle objects in this lane
    - stop_line_pos: (x, y) where cars stop at red light

class Road:
    - direction: NORTH, SOUTH, EAST, WEST
    - lanes: list of Lane objects (incoming + outgoing)
    - get_incoming_lanes(): returns lanes heading toward intersection
    - get_outgoing_lanes(): returns lanes heading away

class Intersection:
    - position: center (x, y) = center of screen
    - roads: dict of 4 Road objects
    - traffic_lights: dict of TrafficLight objects (one per direction)
    - conflict_zone: pygame.Rect defining the intersection box
    - is_in_intersection(vehicle): checks if car is inside
    
    The intersection should be at the CENTER of the screen.
    Roads extend from the intersection to the edges of the screen.
    
    VISUAL LAYOUT (the screen should look like this):
    
                    â”‚ â†“ â”‚ â”‚ â†‘ â”‚
                    â”‚   â”‚ â”‚   â”‚
                    â”‚ S â”‚ â”‚ N â”‚
                    â”‚   â”‚ â”‚   â”‚
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
     â† W    outgoing    â”‚ â”‚    incoming  E â†’
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚ â”‚     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
     â† W    incoming    â”‚ â”‚    outgoing  E â†’
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                    â”‚   â”‚ â”‚   â”‚
                    â”‚ S â”‚ â”‚ N â”‚
                    â”‚   â”‚ â”‚   â”‚
                    â”‚ â†“ â”‚ â”‚ â†‘ â”‚

    Cars spawn at screen edges, drive toward intersection,
    stop at red light, proceed on green, despawn at opposite edge.

=======================================================================
FILE 3: simulation/vehicle.py
=======================================================================

class Vehicle:
    Properties:
    - id: unique identifier
    - x, y: current position (float)
    - width, height: car dimensions
    - color: random from CAR_COLORS
    - speed: random between MIN and MAX
    - max_speed: the assigned speed
    - direction: NORTH, SOUTH, EAST, WEST
    - lane: reference to Lane object
    - state: MOVING, WAITING, CROSSING, DESPAWNED
    - wait_time: frames spent waiting at red light (int)
    - total_time: frames since spawn (int)
    - rect: pygame.Rect for collision/rendering
    
    Methods:
    - update(traffic_light_state):
        * If light is GREEN for this direction â†’ move at speed
        * If light is RED and approaching stop line â†’ decelerate & stop
        * If light is YELLOW â†’ stop if far, continue if close
        * Follow the car ahead (maintain SAFE_DISTANCE)
        * DO NOT enter intersection on RED
        * Increment wait_time if stopped
        * Increment total_time always
        
    - check_front_vehicle(vehicles_in_lane):
        * Find the vehicle directly ahead in same lane
        * If distance < SAFE_DISTANCE â†’ match its speed or stop
        * This prevents cars from overlapping
        
    - has_crossed(): 
        * Returns True if vehicle passed through intersection
        * and reached despawn zone
    
    - draw(screen):
        * Draw a colored rectangle with a darker border
        * Draw small "headlights" (2 small yellow dots) based 
          on direction
        * Car shape should be oriented based on travel direction:
          - NORTH/SOUTH: tall rectangle
          - EAST/WEST: wide rectangle

class VehicleSpawner:
    - spawn_rate: probability per frame per direction
    - spawn_vehicle(direction, lane): creates new Vehicle at 
      screen edge
    - should_spawn(): random check against spawn_rate
    - Ensure new car doesn't spawn ON TOP of existing car
      (check spawn zone is clear)

=======================================================================
FILE 4: simulation/traffic_light.py
=======================================================================

class TrafficLightState(Enum):
    RED = "RED"
    YELLOW = "YELLOW"
    GREEN = "GREEN"

class TrafficLight:
    - direction: NORTH, SOUTH, EAST, WEST
    - state: TrafficLightState
    - timer: frames remaining in current state
    - position: (x, y) for rendering
    - green_duration: configurable
    
    - set_state(new_state, duration)
    - update(): decrement timer
    - is_green(): bool
    - is_red(): bool
    - draw(screen): 
        Draw 3 circles stacked vertically (like real traffic light)
        Only the active light should be bright, others should be dim
        Add a dark rectangular housing behind the circles

class TrafficLightController:
    """Base class for all controllers"""
    - lights: dict of TrafficLight objects
    - current_phase: int
    - phase_timer: int
    
    - get_state(): returns current state of all lights
    - step(): abstract method â€” advance one frame
    - set_phase(phase_id): set which lights are green
    - get_phase_info(): returns human-readable phase description
    
    Phase definitions:
    Phase 0: North-South GREEN, East-West RED
    Phase 1: All YELLOW (transition)
    Phase 2: East-West GREEN, North-South RED
    Phase 3: All YELLOW (transition)

=======================================================================
FILE 5: controllers/timer_controller.py
=======================================================================

class TimerController(TrafficLightController):
    """
    The DUMB baseline controller.
    Simply cycles through phases on a fixed timer.
    No awareness of traffic conditions at all.
    
    Cycle: NS_GREEN (90 frames) â†’ YELLOW (30) â†’ 
           EW_GREEN (90 frames) â†’ YELLOW (30) â†’ repeat
    """
    
    - __init__(lights): set up fixed cycle
    - step(): 
        Decrement timer
        When timer hits 0, move to next phase
        Cycle through phases endlessly
    
    This should work POORLY when traffic is unbalanced
    (lots of cars on one road, few on other)

=======================================================================
FILE 6: controllers/rule_based_controller.py
=======================================================================

class RuleBasedController(TrafficLightController):
    """
    The SMART rule-based controller (our safety net).
    Switches lights based on vehicle density per direction.
    
    Logic:
    1. Count waiting vehicles in each direction
    2. If current green direction has < 3 waiting cars
       AND other direction has > 5 waiting cars
       â†’ Switch to other direction
    3. Minimum green time enforced (MIN_GREEN_DURATION)
    4. Maximum green time enforced (MAX_GREEN_DURATION)
    5. Always transition through YELLOW
    """
    
    - __init__(lights, vehicles_ref): 
        needs reference to vehicle list to count densities
    - count_vehicles(direction): count cars waiting at red
    - calculate_pressure(direction): 
        weighted score = num_cars Ã— 1.0 + avg_wait_time Ã— 0.5
    - step():
        If in YELLOW phase â†’ just count down, then switch
        If in GREEN phase:
            current_pressure = pressure of green direction
            other_pressure = pressure of red direction
            If other_pressure > current_pressure Ã— 1.5 
               AND min_green exceeded:
                â†’ Switch to YELLOW, then give GREEN to other
            If max_green exceeded:
                â†’ Force switch

=======================================================================
FILE 7: ai/dqn_network.py
=======================================================================

import torch
import torch.nn as nn

class DQN(nn.Module):
    """
    Deep Q-Network for traffic light control.
    
    Input (state): vector of size STATE_SIZE (12)
    [north_count, north_avg_wait, north_queue_length,
     south_count, south_avg_wait, south_queue_length,
     east_count,  east_avg_wait,  east_queue_length,
     west_count,  west_avg_wait,  west_queue_length]
    
    Output: Q-values for each action (ACTION_SIZE)
    Action 0: Set North-South to GREEN
    Action 1: Set East-West to GREEN
    
    Architecture:
    - Input layer: STATE_SIZE neurons
    - Hidden layer 1: 128 neurons, ReLU
    - Hidden layer 2: 128 neurons, ReLU
    - Hidden layer 3: 64 neurons, ReLU
    - Output layer: ACTION_SIZE neurons (no activation â€” raw Q-values)
    
    Use Xavier initialization for weights.
    """
    
    Build this as a standard PyTorch nn.Module with forward() method.

=======================================================================
FILE 8: ai/replay_buffer.py
=======================================================================

class ReplayBuffer:
    """
    Experience Replay Memory for DQN.
    
    Stores transitions: (state, action, reward, next_state, done)
    
    Methods:
    - __init__(capacity): initialize with max size
    - push(state, action, reward, next_state, done): 
        add transition, overwrite oldest if full
    - sample(batch_size): 
        return random batch as tensors
    - __len__(): return current size
    
    Use collections.deque for O(1) append/popleft.
    Return samples as PyTorch tensors, properly shaped.
    """

=======================================================================
FILE 9: ai/trainer.py
=======================================================================

class DQNTrainer:
    """
    Handles the complete DQN training loop.
    
    Components:
    - policy_net: the main DQN being trained
    - target_net: frozen copy, updated periodically
    - optimizer: Adam with LEARNING_RATE
    - replay_buffer: ReplayBuffer instance
    - epsilon: current exploration rate
    
    Methods:
    - select_action(state):
        Epsilon-greedy: 
        With probability epsilon â†’ random action
        Otherwise â†’ argmax of policy_net(state)
    
    - optimize():
        If buffer has < BATCH_SIZE samples â†’ return
        Sample batch from replay buffer
        Compute current Q-values: policy_net(state)[action]
        Compute target Q-values: 
            reward + GAMMA * max(target_net(next_state)) * (1 - done)
        Loss = MSE between current and target
        Backpropagate
        Clip gradients to [-1, 1]
    
    - update_target():
        Copy policy_net weights to target_net
    
    - decay_epsilon():
        epsilon = max(EPSILON_END, epsilon * EPSILON_DECAY)
    
    - save_model(path): save policy_net state_dict
    - load_model(path): load policy_net state_dict
    
    - train(env, num_episodes):
        For each episode:
            state = env.reset()
            For each step:
                action = select_action(state)
                next_state, reward, done, info = env.step(action)
                replay_buffer.push(...)
                optimize()
                If step % TARGET_UPDATE_FREQ == 0: update_target()
                decay_epsilon()
            Log episode reward, avg wait time, throughput
            Print progress every 10 episodes
            Save model every 50 episodes
    """

=======================================================================
FILE 10: controllers/dqn_controller.py
=======================================================================

class DQNController(TrafficLightController):
    """
    RL-based controller that uses trained DQN to make decisions.
    
    - __init__(lights, vehicles_ref, model_path):
        Load trained DQN model
        Set epsilon = 0 (no exploration during demo)
    
    - get_state_vector():
        Build the 12-dimensional state vector from current 
        traffic conditions:
        For each direction (N, S, E, W):
            - vehicle_count: number of waiting vehicles
            - avg_wait_time: average wait time of those vehicles
              (normalized by dividing by MAX_GREEN_DURATION)
            - queue_length: length of queue in pixels
              (normalized by dividing by road length)
    
    - step():
        Every DECISION_INTERVAL frames (e.g., every 30 frames):
            state = get_state_vector()
            action = dqn.predict(state)  # argmax Q-value
            If action != current_phase:
                Transition through YELLOW first
                Then apply new phase
        Between decisions:
            Just maintain current phase
        
        Enforce minimum green time before allowing switch.
    """

=======================================================================
FILE 11: simulation/environment.py
=======================================================================

import gymnasium as gym  # or just implement the interface manually

class TrafficEnvironment:
    """
    OpenAI Gym-compatible environment for training.
    
    This wraps the entire simulation into:
    - reset() â†’ initial state
    - step(action) â†’ (next_state, reward, done, info)
    - render() â†’ optional PyGame visualization
    
    State Space: 12-dimensional continuous vector
    Action Space: Discrete(2) â€” NS_green or EW_green
    
    reset():
        - Clear all vehicles
        - Reset all traffic lights to default
        - Spawn initial batch of vehicles
        - Return initial state vector
    
    step(action):
        - Apply action (set traffic light phase)
        - Run simulation for DECISION_INTERVAL frames
          (this means calling vehicle.update() etc. multiple times)
        - Calculate reward:
            reward = 0
            For each vehicle that crossed intersection: 
                reward += REWARD_CAR_PASSED
            For each vehicle still waiting:
                reward += PENALTY_CAR_WAITING
            For any vehicle waiting > 200 frames:
                reward += PENALTY_LONG_WAIT
            If action changed from previous action:
                reward += PENALTY_SWITCH
        - Build new state vector
        - done = True if total_steps > MAX_EPISODE_STEPS (3000)
        - info = {
            'throughput': cars_passed_this_step,
            'avg_wait': average_wait_time,
            'total_waiting': total_cars_waiting,
            'total_passed': total_cars_passed_this_episode
          }
        - Return (state, reward, done, info)
    
    Internal simulation loop (called within step):
        For frame in range(DECISION_INTERVAL):
            spawner.try_spawn_all_directions()
            for vehicle in all_vehicles:
                vehicle.update(traffic_lights)
            remove despawned vehicles
            track metrics
    """

=======================================================================
FILE 12: visualization/renderer.py
=======================================================================

import pygame

class Renderer:
    """
    PyGame rendering engine. Makes everything look BEAUTIFUL.
    
    __init__(width, height):
        Initialize PyGame
        Create screen surface
        Set up fonts (use pygame.font.SysFont)
        Load/create assets
    
    draw_background():
        - Fill screen with dark gray (30, 30, 30)
        - Draw grass/ground patches in dark green (20, 60, 20)
          in the 4 corner quadrants (between roads)
    
    draw_roads():
        - Draw horizontal road as dark gray rectangle across screen
        - Draw vertical road as dark gray rectangle across screen
        - Add lane markings: white dashed lines down the center
        - Add edge lines: solid white lines on road edges
        - Add stop lines: thick white lines at intersection edges
        - Add crosswalk markings (zebra stripes) â€” optional
        - Road color: (50, 50, 50)
        - Lane marking color: (200, 200, 200), dashed
        - Stop line color: (255, 255, 255), solid
    
    draw_intersection():
        - The center box where roads meet
        - Slightly different shade than roads (55, 55, 55)
        - Optional: yellow box junction markings
    
    draw_traffic_lights(lights_dict):
        - For each direction, draw a traffic light housing:
            * Black rounded rectangle background
            * 3 circles: Red, Yellow, Green (top to bottom)
            * Active light = bright color
            * Inactive lights = very dim version of color
            * Add a subtle glow effect around active light
              (draw a larger, semi-transparent circle behind it)
        - Position lights next to the stop lines:
            * North light: above the intersection, right side
            * South light: below the intersection, left side
            * East light: right of intersection, top side
            * West light: left of intersection, bottom side
    
    draw_vehicles(vehicles_list):
        - For each vehicle:
            * Draw car body as rounded rectangle
            * Color = vehicle's assigned color
            * Add darker border (2px)
            * Add headlights: 2 small yellow dots at front
            * Add taillights: 2 small red dots at back
            * Front/back depends on direction:
                NORTH â†’ front is top
                SOUTH â†’ front is bottom
                EAST â†’ front is right
                WEST â†’ front is left
            * If vehicle is WAITING, add small red indicator
              (brake lights brighter)
    
    draw_ui_overlay(metrics, controller_name, mode):
        """Draw the heads-up display with live stats"""
        
        TOP BAR (semi-transparent dark rectangle at top):
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  ğŸš¦ Traffic-Mind    [Mode: AI/Timer/Smart]       â”‚
        â”‚  FPS: 60  |  Time: 02:34  |  Cars: 45           â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        
        LEFT PANEL (semi-transparent, left side):
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   ğŸ“Š Live Stats     â”‚
        â”‚                     â”‚
        â”‚   Throughput: 12/s  â”‚
        â”‚   Avg Wait: 3.2s   â”‚
        â”‚   Max Wait: 8.1s   â”‚
        â”‚   Queue N: â–ˆâ–ˆâ–ˆâ–ˆâ–‘ 8 â”‚
        â”‚   Queue S: â–ˆâ–ˆâ–‘â–‘â–‘ 4 â”‚
        â”‚   Queue E: â–ˆâ–‘â–‘â–‘â–‘ 2 â”‚
        â”‚   Queue W: â–ˆâ–ˆâ–ˆâ–‘â–‘ 6 â”‚
        â”‚                     â”‚
        â”‚   Total Passed: 234 â”‚
        â”‚   Total Waiting: 20 â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        
        Draw the queue bars as colored bar charts:
        - Green bar if queue < 5
        - Yellow bar if queue 5-10
        - Red bar if queue > 10
        
        BOTTOM BAR (controller mode buttons):
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  [1] Timer Mode  [2] Smart Mode  [3] AI Mode    â”‚
        â”‚  [R] Reset  [+/-] Traffic Density  [H] Hardware  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        
        Highlight the active mode button.
    
    draw_comparison_graph(history):
        """Optional: small real-time line graph showing
        throughput over time for current controller"""
        - Bottom-right corner
        - X axis: time (last 300 frames)
        - Y axis: throughput (cars/interval)
        - Line color matches controller mode:
          Timer = Red, Smart = Yellow, AI = Green
    
    render_frame(roads, vehicles, lights, metrics, mode):
        """Called every frame â€” draws everything"""
        draw_background()
        draw_roads()
        draw_intersection()
        draw_vehicles(vehicles)
        draw_traffic_lights(lights)
        draw_ui_overlay(metrics, mode)
        pygame.display.flip()

=======================================================================
FILE 13: visualization/dashboard.py
=======================================================================

class Dashboard:
    """
    Tracks and provides all metrics for the UI overlay.
    
    Tracked metrics:
    - throughput_history: list of cars passed per interval
    - wait_time_history: list of avg wait times per interval
    - queue_lengths: dict of current queue per direction
    - total_cars_passed: int
    - total_cars_spawned: int
    - current_avg_wait: float
    - current_max_wait: float
    - fps: current FPS
    - elapsed_time: seconds since simulation start
    - controller_name: current controller name string
    
    Methods:
    - update(vehicles, passed_vehicles): called every frame
    - get_metrics(): returns dict of all current metrics
    - get_direction_stats(direction): returns dict for one direction
    - reset(): clear all history
    - get_comparison_data(): returns data for comparison chart
    
    Also track per-controller historical performance:
    - timer_total_throughput
    - smart_total_throughput
    - ai_total_throughput
    So we can show comparison at the end.
    """

=======================================================================
FILE 14: hardware/arduino_bridge.py
=======================================================================

import serial
import time

class ArduinoBridge:
    """
    Manages serial communication between Python and Arduino.
    
    Protocol:
    Python sends single characters to Arduino:
    - '0' = North-South GREEN, East-West RED
    - '1' = East-West GREEN, North-South RED
    - '2' = All YELLOW (transition)
    - '3' = All RED (emergency)
    - '9' = Request sensor data
    
    Arduino sends back (when requested):
    - "N:5,S:3,E:8,W:2\n"  (vehicle counts from IR sensors)
    
    Methods:
    - __init__(port, baud_rate):
        Try to connect to Arduino
        If fails, set hardware_available = False (graceful fallback)
        Wait 2 seconds for Arduino to reset
    
    - send_phase(phase_id):
        Send phase character to Arduino
        Small delay (50ms) between sends to avoid flooding
    
    - read_sensors():
        Send '9' to request data
        Read response line
        Parse "N:5,S:3,E:8,W:2" into dict
        Return {NORTH: 5, SOUTH: 3, EAST: 8, WEST: 2}
        If timeout â†’ return None
    
    - sync_with_simulation(traffic_lights):
        """Called every frame â€” syncs LED states with simulation"""
        Determine current phase from traffic light states
        Send appropriate command to Arduino
    
    - close():
        Close serial connection safely
    
    - is_connected(): bool
    
    IMPORTANT: All serial operations must be wrapped in try/except.
    If Arduino is not connected, the software should work fine 
    without it. Never crash because of hardware issues.
    """

=======================================================================
FILE 15: hardware/traffic_light.ino
=======================================================================

WRITE COMPLETE ARDUINO CODE:

/*
 * Traffic-Mind: Arduino Traffic Light Controller
 * 
 * WIRING:
 * North Traffic Light:
 *   Pin 2 = Red LED
 *   Pin 3 = Yellow LED
 *   Pin 4 = Green LED
 * 
 * South Traffic Light:
 *   Pin 5 = Red LED
 *   Pin 6 = Yellow LED
 *   Pin 7 = Green LED
 * 
 * East Traffic Light:
 *   Pin 8 = Red LED
 *   Pin 9 = Yellow LED
 *   Pin 10 = Green LED
 * 
 * West Traffic Light:
 *   Pin 11 = Red LED
 *   Pin 12 = Yellow LED
 *   Pin 13 = Green LED
 * 
 * IR Sensors (OPTIONAL):
 *   A0 = North sensor
 *   A1 = South sensor
 *   A2 = East sensor
 *   A3 = West sensor
 * 
 * PROTOCOL:
 * Receives single char from Python:
 *   '0' = NS Green, EW Red
 *   '1' = EW Green, NS Red
 *   '2' = All Yellow
 *   '3' = All Red
 *   '9' = Send sensor readings back
 * 
 * Sends sensor data when requested:
 *   "N:{val},S:{val},E:{val},W:{val}\n"
 */

Setup:
- Set all LED pins as OUTPUT
- Set all sensor pins as INPUT
- Serial.begin(9600)
- Start with all RED

Loop:
- Check Serial.available()
- Read command character
- Switch on command:
    '0': setPhase_NS_Green()
    '1': setPhase_EW_Green()
    '2': setPhase_AllYellow()
    '3': setPhase_AllRed()
    '9': readAndSendSensors()

Helper functions:
- setLight(redPin, yellowPin, greenPin, state):
    Turn on only the correct LED for given state
- setPhase_NS_Green():
    North & South = GREEN
    East & West = RED
- setPhase_EW_Green():
    East & West = GREEN
    North & South = RED
- setPhase_AllYellow():
    All four = YELLOW
- readAndSendSensors():
    Read analog values from A0-A3
    Convert to "vehicle count" (threshold-based: >500 = car present)
    Send formatted string via Serial

=======================================================================
FILE 16: analytics/metrics.py
=======================================================================

class MetricsCollector:
    """
    Collects and computes all performance metrics.
    
    Per-frame tracking:
    - vehicles_waiting_per_direction: dict
    - vehicles_passed_per_direction: dict
    - wait_times: list of all wait times for passed vehicles
    
    Computed metrics:
    - throughput: cars passed per 100 frames
    - average_wait_time: mean of all wait times
    - max_wait_time: worst case wait time
    - queue_lengths: per direction
    - congestion_index: 
        (total_waiting_cars) / (total_capacity) â€” 0 to 1
    - efficiency_score:
        throughput / max_theoretical_throughput â€” percentage
    
    Comparison methods:
    - compare_controllers(timer_metrics, smart_metrics, ai_metrics):
        Returns formatted comparison dict showing improvement %
        Example:
        {
            'throughput_improvement': '+45% vs Timer',
            'wait_time_reduction': '-62% vs Timer',
            'max_wait_reduction': '-78% vs Timer'
        }
    
    - generate_report():
        Returns formatted string with all stats
        For the presentation slide
    
    - get_chart_data():
        Returns lists suitable for matplotlib plotting
        (for generating comparison charts)
    """

=======================================================================
FILE 17: main.py â€” THE MAIN ENTRY POINT
=======================================================================

"""
Traffic-Mind: AI-Powered Traffic Light Controller
Main application â€” run this to start.

Usage:
    python main.py              # Normal mode (GUI simulation)
    python main.py --train      # Training mode (faster, no render)
    python main.py --demo       # Demo mode (preset scenarios)
    python main.py --hardware   # Enable Arduino connection
"""

import argparse
import pygame
import sys

def main():
    Parse command line arguments
    
    Initialize PyGame
    Initialize Renderer
    Initialize Road Network (single intersection)
    Initialize Vehicle Spawner
    Initialize Traffic Lights
    Initialize Dashboard
    
    # Initialize all three controllers
    timer_ctrl = TimerController(lights)
    smart_ctrl = RuleBasedController(lights, vehicles)
    
    # Try to load trained DQN model
    try:
        dqn_ctrl = DQNController(lights, vehicles, 'models/best_model.pth')
    except FileNotFoundError:
        print("No trained model found. Train first with --train")
        dqn_ctrl = None
    
    # Set default controller
    active_controller = timer_ctrl
    mode_name = "Timer (Dumb)"
    
    # Try Arduino connection if --hardware flag
    arduino = None
    if args.hardware:
        arduino = ArduinoBridge(SERIAL_PORT, BAUD_RATE)
        if arduino.is_connected():
            print("âœ… Arduino connected!")
        else:
            print("âš ï¸ Arduino not found. Running software-only.")
    
    # Main game loop
    clock = pygame.time.Clock()
    running = True
    spawn_rate = SPAWN_RATE_MEDIUM
    
    while running:
        # EVENT HANDLING
        for event in pygame.event.get():
            if event.type == pygame.QUIT:
                running = False
            
            if event.type == pygame.KEYDOWN:
                # MODE SWITCHING
                if event.key == pygame.K_1:
                    active_controller = timer_ctrl
                    mode_name = "Timer (Dumb)"
                    print("Switched to TIMER mode")
                
                if event.key == pygame.K_2:
                    active_controller = smart_ctrl
                    mode_name = "Smart (Rule-Based)"
                    print("Switched to SMART mode")
                
                if event.key == pygame.K_3 and dqn_ctrl:
                    active_controller = dqn_ctrl
                    mode_name = "AI (DQN)"
                    print("ğŸ¤– Switched to AI mode!")
                
                # TRAFFIC DENSITY CONTROLS
                if event.key == pygame.K_PLUS or event.key == pygame.K_EQUALS:
                    spawn_rate = min(spawn_rate + 0.01, 0.1)
                    print(f"Traffic density: {spawn_rate:.2f}")
                
                if event.key == pygame.K_MINUS:
                    spawn_rate = max(spawn_rate - 0.01, 0.01)
                    print(f"Traffic density: {spawn_rate:.2f}")
                
                # RESET
                if event.key == pygame.K_r:
                    vehicles.clear()
                    dashboard.reset()
                    print("Reset!")
                
                # HARDWARE TOGGLE
                if event.key == pygame.K_h and arduino:
                    arduino.hardware_enabled = not arduino.hardware_enabled
                    print(f"Hardware: {'ON' if arduino.hardware_enabled else 'OFF'}")
        
        # SIMULATION UPDATE
        spawner.set_rate(spawn_rate)
        spawner.try_spawn_all_directions(vehicles)
        
        # Update all vehicles
        for vehicle in vehicles[:]:  # copy list to allow removal
            vehicle.update(active_controller.get_state())
            if vehicle.has_crossed():
                dashboard.record_passed(vehicle)
                vehicles.remove(vehicle)
        
        # Update traffic light controller
        active_controller.step()
        
        # Update dashboard
        dashboard.update(vehicles)
        
        # Sync hardware
        if arduino and arduino.is_connected() and arduino.hardware_enabled:
            arduino.sync_with_simulation(active_controller.lights)
        
        # RENDER
        renderer.render_frame(
            roads=road_network,
            vehicles=vehicles,
            lights=active_controller.lights,
            metrics=dashboard.get_metrics(),
            mode=mode_name
        )
        
        clock.tick(FPS)
    
    # Cleanup
    if arduino:
        arduino.close()
    pygame.quit()
    sys.exit()

if __name__ == "__main__":
    main()

=======================================================================
FILE 18: train.py â€” TRAINING SCRIPT
=======================================================================

"""
Training script for DQN agent.
Run this before the demo to train the model.

Usage:
    python train.py --episodes 500 --render
    python train.py --episodes 1000  (no rendering = faster)
"""

def train():
    Parse arguments (episodes, render flag, save_path)
    
    Create TrafficEnvironment
    Create DQNTrainer
    
    print("ğŸš¦ Starting Training...")
    print(f"   Episodes: {args.episodes}")
    print(f"   State size: {STATE_SIZE}")
    print(f"   Action size: {ACTION_SIZE}")
    
    best_reward = -float('inf')
    reward_history = []
    
    for episode in range(args.episodes):
        state = env.reset()
        total_reward = 0
        steps = 0
        
        while True:
            action = trainer.select_action(state)
            next_state, reward, done, info = env.step(action)
            trainer.replay_buffer.push(state, action, reward, 
                                        next_state, done)
            trainer.optimize()
            
            total_reward += reward
            state = next_state
            steps += 1
            
            if steps % TARGET_UPDATE_FREQ == 0:
                trainer.update_target()
            
            if args.render:
                env.render()
            
            if done:
                break
        
        trainer.decay_epsilon()
        reward_history.append(total_reward)
        
        # Save best model
        if total_reward > best_reward:
            best_reward = total_reward
            trainer.save_model('models/best_model.pth')
        
        # Periodic save
        if episode % 50 == 0:
            trainer.save_model(f'models/checkpoint_{episode}.pth')
        
        # Logging
        if episode % 10 == 0:
            avg_reward = sum(reward_history[-10:]) / 10
            print(f"Episode {episode:4d} | "
                  f"Reward: {total_reward:7.1f} | "
                  f"Avg(10): {avg_reward:7.1f} | "
                  f"Epsilon: {trainer.epsilon:.3f} | "
                  f"Throughput: {info['total_passed']:4d} | "
                  f"Avg Wait: {info['avg_wait']:5.1f}")
    
    print(f"\nâœ… Training complete! Best reward: {best_reward:.1f}")
    print(f"   Model saved to: models/best_model.pth")
    
    # Plot training curve
    plot_training_curve(reward_history)

=======================================================================
FILE 19: demo.py â€” ONE-CLICK HACKATHON DEMO
=======================================================================

"""
ğŸ† HACKATHON DEMO SCRIPT
Run this during your presentation. It tells a story.

python demo.py

The demo runs in 3 acts:
Act 1: "The Problem" â€” Timer mode, heavy traffic, chaos builds
Act 2: "Our Solution" â€” Switch to AI, traffic clears dramatically
Act 3: "The Results" â€” Show comparison stats

Each act transitions automatically with on-screen text.
"""

def demo():
    Initialize everything
    Load trained model
    
    # ACT 1: THE PROBLEM (45 seconds)
    show_title_card("Act 1: The Problem", 
                    "Fixed-timer traffic lights cause jams", 3)
    
    Set controller to TimerController
    Set spawn_rate to HIGH
    Run for 45 seconds (2700 frames at 60fps)
    Record timer_metrics
    
    # Show transition text
    show_title_card("Now watch what happens when we turn on AI...", 
                    "", 3)
    
    # ACT 2: THE SOLUTION (45 seconds)  
    show_title_card("Act 2: AI Takes Control ğŸ¤–", 
                    "Deep Q-Network Reinforcement Learning", 3)
    
    Switch controller to DQNController
    Keep spawn_rate HIGH
    Run for 45 seconds
    Record ai_metrics
    
    # Watch the queues dissolve dramatically!
    
    # ACT 3: THE RESULTS (15 seconds)
    show_title_card("Act 3: Results", "", 2)
    
    Show full-screen comparison:
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚         TIMER MODE    vs    AI MODE          â”‚
    â”‚                                              â”‚
    â”‚ Throughput:   12/min  â†’â†’â†’   22/min  (+83%)  â”‚
    â”‚ Avg Wait:     34 sec  â†’â†’â†’   8 sec   (-76%)  â”‚
    â”‚ Max Wait:     89 sec  â†’â†’â†’   15 sec  (-83%)  â”‚
    â”‚ Congestion:   HIGH    â†’â†’â†’   LOW              â”‚
    â”‚                                              â”‚
    â”‚       ğŸ† AI Reduced Congestion by 76% ğŸ†     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    Wait for keypress to exit.

    # The show_title_card function:
    # Fades in text on a dark overlay on top of the simulation
    # Uses large font for title, smaller font for subtitle
    # Displays for specified seconds then fades out

=======================================================================
FILE 20: requirements.txt
=======================================================================

pygame>=2.5.0
torch>=2.0.0
numpy>=1.24.0
pyserial>=3.5
matplotlib>=3.7.0

=======================================================================
FILE 21: README.md
=======================================================================

Write a professional README with:

# ğŸš¦ Traffic-Mind: AI-Powered Traffic Light Controller

## ğŸ† Built for [Trident Academy Hackathon]

### The Problem
Traffic lights today are timer-based. They cycle on fixed intervals 
regardless of actual traffic conditions, causing unnecessary 
congestion at intersections.

### Our Solution
Traffic-Mind is an AI Agent that CONTROLS traffic lights in 
real-time based on vehicle density, using Deep Q-Network 
Reinforcement Learning. It doesn't just predict traffic â€” 
it actively fixes it.

### Key Features
- ğŸ® Real-time traffic simulation built with PyGame
- ğŸ¤– DQN Reinforcement Learning agent
- ğŸ“Š Live performance dashboard
- ğŸ”§ Arduino hardware integration (LED traffic lights + IR sensors)
- ğŸ“ˆ Side-by-side comparison: Timer vs Rule-Based vs AI

### Demo
[Screenshots / GIF placeholder]

### Tech Stack
- Python, PyGame, PyTorch
- Arduino (C++) for hardware
- DQN (Deep Q-Network) for RL

### How to Run
```bash
pip install -r requirements.txt
python train.py --episodes 500    # Train the AI
python main.py                    # Run simulation
python demo.py                    # Hackathon demo
```

### Team
[Names]

### Results
| Metric | Timer | AI | Improvement |
|--------|-------|-----|------------|
| Throughput | X/min | Y/min | +Z% |
| Avg Wait | X sec | Y sec | -Z% |

=======================================================================
CRITICAL IMPLEMENTATION NOTES:
=======================================================================

1. VEHICLE MOVEMENT MUST LOOK REALISTIC:
   - Cars must follow each other (no overlapping)
   - Cars must decelerate smoothly when approaching red light
   - Cars must accelerate smoothly when light turns green
   - Cars in the front of the queue move first

2. VISUAL QUALITY MATTERS:
   - Use anti-aliased drawing where possible
   - Smooth colors, dark theme (looks professional)
   - Car headlights and taillights add life
   - Traffic light glow effect makes it pop
   - Semi-transparent UI panels look modern

3. THE "WOW MOMENT" IN THE DEMO:
   - When AI mode is activated, the backed-up queues should 
     visibly shrink within 10-15 seconds
   - This happens because the AI gives GREEN to the direction 
     with the most waiting cars
   - The timer controller ignores this, keeping GREEN on 
     empty roads while cars pile up elsewhere

4. FALLBACK STRATEGY:
   - If DQN training fails or doesn't converge:
     The RuleBasedController already looks impressive
   - It switches based on density, which is dramatically 
     better than the timer
   - Label it "AI Mode" for the demo if needed (it IS smart)

5. PERFORMANCE:
   - Keep vehicles list under MAX_VEHICLES (200)
   - Use spatial hashing or simple checks for collision
   - Target 60 FPS for smooth demo
   - Don't render during training (much faster)

6. ARDUINO SAFETY:
   - All hardware code must be wrapped in try/except
   - If Arduino disconnects mid-demo, software continues fine
   - Print "Hardware disconnected" warning, don't crash

=======================================================================
NOW: Generate ALL files, COMPLETE code, EVERY line. 
Start with config/settings.py and go through each file in order.
Do NOT skip any file. Do NOT use placeholder comments like 
"implement this." Write REAL, WORKING, COMPLETE code.
=======================================================================
```

---

## ğŸ¯ How to Use This Prompt

### Step-by-Step Instructions

```
STEP 1: Open GitHub Copilot Chat (or VS Code with Copilot)
        OR use Claude / ChatGPT / any AI coding assistant

STEP 2: Create the folder structure first:
        mkdir traffic-mind
        cd traffic-mind
        mkdir config simulation controllers ai hardware 
              visualization analytics models

STEP 3: Paste the ENTIRE prompt above into Copilot Chat

STEP 4: If it's too long, split by file:
        "Generate FILE 1: config/settings.py as described above"
        "Now generate FILE 2: simulation/road_network.py"
        ... and so on

STEP 5: After all files are generated:
        pip install -r requirements.txt
        python train.py --episodes 300 --render
        python main.py

STEP 6: If training takes too long for hackathon:
        Just use the Rule-Based controller
        It already looks impressive!
```

### If Copilot Truncates (Gives Partial Code)

```
Say this:
"Continue generating the code for [filename]. 
 You stopped at [last line]. 
 Complete the entire file."

Or split requests:
"Generate ONLY simulation/vehicle.py â€” complete code"
"Generate ONLY ai/dqn_network.py â€” complete code"
```

---

## â±ï¸ Hackathon Timeline Using This Prompt

```
HOUR 0-1:   Generate all code files using prompt
HOUR 1-2:   Fix imports, test basic PyGame window opens
HOUR 2-4:   Get vehicles spawning and moving on screen
HOUR 4-6:   Get traffic lights working with timer controller
HOUR 6-8:   Implement rule-based controller + comparison
HOUR 8-12:  Train DQN (run train.py in background)
HOUR 12-16: Arduino hardware setup + wiring
HOUR 16-20: Polish visuals + dashboard + demo script
HOUR 20-24: Practice presentation + backup plans

YOU HAVE A WORKING DEMO BY HOUR 8 (with rule-based).
DQN is a BONUS that trains while you polish everything else.
```

> **This prompt is your entire hackathon project blueprint. Every file, every function, every feature â€” all in one place.** ğŸš€
